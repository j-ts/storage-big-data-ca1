{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304adcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import  when, col, to_date, unix_timestamp, regexp_replace \n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "spark = (SparkSession.builder \\\n",
    "    .appName(\"Tokyo Airbnb Analysis\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")  \n",
    "    #.config(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    .config(\"spark.network.timeout\", \"600s\") \n",
    "    .config(\"spark.executor.heartbeatInterval\", \"120s\") \n",
    "    .getOrCreate())\n",
    "\n",
    "dataset_path = \"/user1/dataset/calendar.csv\"\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = spark.read.csv(dataset_path, header=True, inferSchema=True)\n",
    "df.show()\n",
    "\n",
    "\n",
    "df = df.withColumn(\"price\", regexp_replace(col(\"price\"), \"[\\$,]\", \"\").cast(FloatType()))\n",
    "df = df.withColumn(\"available\", when(col(\"available\") == \"t\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"date_unix\", unix_timestamp(\"date\"))\n",
    "\n",
    "df = df.withColumn(\"date\", to_date(df.date, 'yyyy-MM-dd')).orderBy(col(\"date\"))\n",
    "\n",
    "\n",
    "# StringIndexer for the 'listing_id' if it's categorical\n",
    "indexer = StringIndexer(inputCol=\"listing_id\", outputCol=\"listing_id_indexed\")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\"listing_id\", #\"year\", \"month\", \"day\", \n",
    "                                       'date_unix', \"price\"], outputCol=\"features\")\n",
    "\n",
    "df = df.drop(*['adjusted_price', 'minimum_nights', 'maximum_nights', 'date'])\n",
    "df = df.limit(10000)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "\n",
    "# Train a classification model\n",
    "classifier = RandomForestClassifier(labelCol=\"available\", featuresCol=\"features\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, classifier])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train_data)\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"available\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bedf9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/19 02:26:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder \\\n",
    "    .appName(\"Tokyo Airbnb Analysis\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")  \n",
    "    #.config(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    .config(\"spark.network.timeout\", \"600s\") \n",
    "    .config(\"spark.executor.heartbeatInterval\", \"120s\") \n",
    "    .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fac61c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+----------+--------------+--------------+--------------+\n",
      "|listing_id|      date|available|     price|adjusted_price|minimum_nights|maximum_nights|\n",
      "+----------+----------+---------+----------+--------------+--------------+--------------+\n",
      "|    197677|2023-06-29|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-06-30|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-01|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-02|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-03|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-04|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-05|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-06|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-07|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-08|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-09|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-10|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-11|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-12|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-13|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-14|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-15|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-16|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-17|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "|    197677|2023-07-18|        f|$11,000.00|    $11,000.00|             3|          1125|\n",
      "+----------+----------+---------+----------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/user1/dataset/calendar.csv\"\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = spark.read.csv(dataset_path, header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn(\"price\", regexp_replace(col(\"price\"), \"[\\$,]\", \"\").cast(FloatType()))\n",
    "df = df.withColumn(\"available\", when(col(\"available\") == \"t\", 1).otherwise(0)) \\\n",
    "    .withColumn(\"date_unix\", unix_timestamp(\"date\"))\n",
    "\n",
    "df = df.withColumn(\"date\", to_date(df.date, 'yyyy-MM-dd')).orderBy(col(\"date\"))\n",
    "\n",
    "\n",
    "# StringIndexer for the 'listing_id' if it's categorical\n",
    "indexer = StringIndexer(inputCol=\"listing_id\", outputCol=\"listing_id_indexed\")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\"listing_id\", #\"year\", \"month\", \"day\", \n",
    "                                       'date_unix', \"price\"], outputCol=\"features\")\n",
    "\n",
    "df = df.drop(*['adjusted_price', 'minimum_nights', 'maximum_nights', 'date'])\n",
    "df = df.limit(10000)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f313ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classification model\n",
    "classifier = RandomForestClassifier(labelCol=\"available\", featuresCol=\"features\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, assembler, classifier])\n",
    "\n",
    "# Train the model\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"available\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a525b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c9c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
