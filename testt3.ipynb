{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304adcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import month, year, col, explode\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Tokyo Airbnb Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a309a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = spark.read.csv(\"/user1/dataset/calendar.csv\", header=True, inferSchema=True)\n",
    "df_calendar = df_calendar.withColumn(\"date\", to_date(df_calendar.date, 'yyyy-MM-dd'))\n",
    "df_calendar.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17843e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_busy_times = df_calendar.where(col(\"available\") == 'f') \\\n",
    "                  .groupBy(year(\"date\").alias(\"year\"), month(\"date\").alias(\"month\")) \\\n",
    "                  .count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_busy_times = df_calendar.where(col(\"available\") == 'f') \\\n",
    "                  .groupBy(year(\"date\").alias(\"year\"), month(\"date\").alias(\"month\")) \\\n",
    "                  .count() \\\n",
    "                  .orderBy(\"year\", \"month\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70e9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a011e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df_busy_times.toPandas()\n",
    "pandas_df.sort_values(['year', 'month', 'year'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06038c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas_df.plot(x='month', y='count', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815b8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615cf52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_data = '/user1/dataset/neighbourhoods.geojson'\n",
    "# Load the main data set into pyspark data frame \n",
    "df = spark.read.json(filename_data, mode=\"DROPMALFORMED\")\n",
    "print('Data frame type: ' + str(type(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('++Data overview+++')\n",
    "df.printSchema()\n",
    "print('++Columns overview++')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"features\", explode(col(\"features\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('++Columns overview++')\n",
    "pd.DataFrame(df.dtypes, columns = ['Column Name','Data type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d66363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"features.properties.neighbourhood\", \"features.geometry.type\").show(2, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d35123",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_geometry_types = df.select(\"features.geometry.type\").distinct()\n",
    "distinct_geometry_types.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f994c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_geometry_types = df.select(\"features.properties\").distinct()\n",
    "distinct_geometry_types.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ff124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping the 'neighbourhood_group' because it's null\n",
    "df = df.withColumn(\"features\", col(\"features\").withField(\"properties\",\n",
    "    col(\"features.properties\").dropFields(\"neighbourhood_group\")))\n",
    "\n",
    "# print updated schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_dict = df.select(\"features.\").toJSON()\n",
    "import json\n",
    "\n",
    "json_strings = geojson_dict.collect()\n",
    "\n",
    "# Create a GeoJSON structure from the collected JSON strings\n",
    "geojson_features = [json.loads(j) for j in json_strings]\n",
    "\n",
    "geojson_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": geojson_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newrdd = geojson_dict.map(lambda x : (x[0],x))\n",
    "\n",
    "a = newrdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc643595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e27c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the map with the central location\n",
    "m = folium.Map(location=[35.7002, 139.8738], zoom_start=9)\n",
    "\n",
    "# Add the GeoJSON layer\n",
    "folium.GeoJson(\n",
    "    geojson_data,\n",
    "    style_function=lambda x: {\n",
    "        'fillColor': 'orange',\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'fillOpacity': 0.5},\n",
    "    name='GeoJSON Layer').add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a463b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf903a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
